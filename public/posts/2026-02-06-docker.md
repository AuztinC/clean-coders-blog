---
title: "Docker"
date: "2026-02-06"
---

# A day of containers, confusion, and clarity

The post I wrote about picking up C# again came from a familiar place: scrolling job listings, feeling underqualified in languages I can reason about, and trying to regain confidence by doing something concrete. Today was an extension of that same instinct—except instead of Euler problems and test runners, the battlefield was Docker.

On paper, the goal was simple: take the small C# API I’ve been building and run it in a container. In practice, the day was a tour through several layers of abstraction I thought I understood, but clearly didn’t yet. The first hurdle was conceptual: what exactly is the difference between a Dockerfile and Docker Compose? My minor experience with these things was mostly as a pair with a Craftsman during my apprenticeship. Today forced me to slow down and really understand what is happening.

A Dockerfile, I finally internalized, is about how to build a single image. It’s a recipe. Base image, working directory, copy files, build, publish, run. Linear. Deterministic. Honest.

Docker Compose, on the other hand, is about how multiple containers live together. It doesn’t replace the Dockerfile but instead orchestrates it. It answers questions like:

Which services exist?
How do they talk to each other?
Which ports are exposed?
What volumes persist data?

Docker Compose also helps reduce the need for long and complicated run commands like:
```bash
docker run --name tasks-api -p 8080:8080 \            
  -e MigrateOnStartup=true \
  -e "ConnectionStrings__TaskBoardDb=Data Source=/data/taskboard.db" \
  -v taskboard-data:/data \
  tasks-api-image
```
Which instead becomes a simple `docker-compose up`

Once that distinction clicked, a lot of earlier confusion made sense. I had been expecting Compose to “fix” build problems that were really Dockerfile problems. That’s like yelling at Kubernetes because your program doesn’t compile. Then came my struggle with understanding port handling.

Inside the container, my API was listening on one port. Outside the container, Docker was exposing another. ASP.NET had opinions. Kestrel had opinions. I had assumptions. The assumptions lost.

I had cases where:

-- /ping worked but /tasks exploded with a 500

-- the container was running, but nothing responded

-- logs suggested migrations should have run… but clearly hadn’t

At one point I was convinced something was fundamentally wrong with EF Core, SQLite, or my query logic. The truth was less dramatic and more humbling when I realized that I had changed environment variables, volume paths, and startup behavior—but forgot to rebuild the image.

The moment I rebuilt it, everything worked.

That mistake stung, but it was also clarifying. Docker is unforgiving in a way that’s actually healthy. It doesn’t care what you meant and only cares what you built. If you don’t rebuild, you are literally running yesterday’s thoughts.

By the end of the day, I wasn’t just “using Docker” I was starting to reason about it. I could explain why the API listened on one port internally and another externally. I understood why migrations belonged at startup and why they can silently fail if your database path points somewhere ephemeral. I could read the logs without guessing.

Most importantly, the deflation I felt earlier in the week had shifted. Not disappeared—but shifted into something more useful. Struggle doesn’t mean stagnation. Often it just means you’ve finally hit the layer where real understanding lives.

Today wasn’t smooth. It wasn’t fast. But it was honest progress.. the kind that sticks.

*![Tic-Tac-Toe inside of WoW](../images/docker-lifecycle.png)*
[Microsoft Dotnet Docker Workflow](https://learn.microsoft.com/en-us/dotnet/architecture/microservices/docker-application-development-process/docker-app-development-workflow?utm_source=chatgpt.com)